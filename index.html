<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Long-Video Audio Synthesis with Multi-Agent Collaboration</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Long-Video Audio Synthesis with Multi-Agent Collaboration</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                Yehang Zhang<sup>1 *</sup>, </span>
                <!-- <span class="author-block">
                  <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Yehang Zhang</a><sup>*</sup>,</span> -->
              <span class="author-block">
                Xinli Xu<sup>1 *</sup>, </span>
              <span class="author-block">
                Xiaojie Xu<sup>1 *</sup>, </span>
              <span class="author-block">
                Li Liu<sup>1,2 †</sup>, </span>
              <span class="author-block">
                Yingcong Chen<sup>1,2 †</sup></span>
            </div>
                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>HKUST(GZ), <sup>2</sup>HKUST</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup> Indicates Equal Contribution, </small> <small><sup>†</sup> Co-corresponding author</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2503.10719" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="ai ai-arxiv"></i>
                        </span>
                        <span>ArXiv</span>
                      </a>
                    </span>
                    
                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->
                  
                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/ZYH-Lightyear/LVAS" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Demo link -->
                <span class="link-block">
                  <a href="https://www.gradio.app/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-desktop"></i>
                    </span>
                    <span>Demo (Coming soon)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Video-to-audio synthesis, which generates synchronized audio for visual content, critically enhances viewer immersion and narrative coherence in film and interactive media. However, video-to-audio dubbing for long-form content remains an unsolved challenge due to dynamic semantic shifts, temporal misalignment, and the absence of dedicated datasets. While existing methods excel in short videos, they falter in long scenarios (e.g., movies) due to fragmented synthesis and inadequate cross-scene consistency. We propose LVAS-Agent, a novel multi-agent framework that emulates professional dubbing workflows through collaborative role specialization. Our approach decomposes long-video synthesis into four steps including scene segmentation, script generation, sound design and audio synthesis. Central innovations include a discussion-correction mechanism for scene/script refinement and a generation-retrieval loop for temporal-semantic alignment. To enable systematic evaluation, we introduce LVAS-Bench, the first benchmark with 207 professionally curated long videos spanning diverse scenarios. Experiments demonstrate superior audio-visual alignment over baseline methods.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/show_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Every part of the video is generated at one time by the LVAS-Agent. The video types include: anime fight scenes, video games, real-life videos, and AIGC videos.  
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Framework Image Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3 has-text-centered">Framework</h2>
        <div class="content has-text-centered">
          <figure class="image">
            <!-- Update the path to your actual framework image -->
            <img src="static/images/framework.png" alt="LVAS-Agent Framework">
          </figure>
          <p class="caption">
            Figure 1: Overview of our LVAS-Agent multi-agent collaboration framework for long-video audio synthesis.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Framework Image Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full">
        <h2 class="title is-3 has-text-centered">LVAS-Bench</h2>
        <div class="content has-text-centered">
          <figure class="image">
            <!-- Update the path to your actual framework image -->
            <img src="static/images/benchmark.png" alt="LVAS-Bench">
          </figure>
          <p class="caption">
            Figure 2: Our LVAS-Bench is presented in the following parts: (a) illustrates sample data from the benchmark, (b) provides statisticaldistributions of audio categories and sub-categories across the dataset, and (c) presents the statistics of video categories within the dataset.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/carousel1.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div> -->
      <!-- <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/carousel2.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item"> -->
        <!-- Your image here -->
        <!-- <img src="static/images/carousel3.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item"> -->
      <!-- Your image here -->
      <!-- <img src="static/images/carousel4.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description. -->
      <!-- </h2> -->
    <!-- </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->

<!-- Video Comparison Section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Comparison with Baseline</h2>
      <p class="subtitle has-text-centered">Our method (right) achieves better audio-visual alignment compared to baseline methods (left)</p>
      
      <!-- Video comparison rows -->
      <div class="columns is-centered mb-6">
        <div class="column is-5">
          <h4 class="title is-5 has-text-centered">MMAudio</h4>
          <video class="comparison-video" controls muted loop height="100%">
            <source src="static/videos/mmaudio_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <p class="has-text-centered mt-2">Prompt: Wind, Tanks moving, Tanks firing</p>
        </div>
        <div class="column is-5">
          <h4 class="title is-5 has-text-centered">Our Method</h4>
          <video class="comparison-video" controls muted loop height="100%">
            <source src="static/videos/lvas_agent_1.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <p class="has-text-centered mt-2">Our method achieves better temporal-semantic alignment</p>
        </div>
      </div>
      
      <div class="columns is-centered mb-6">
        <div class="column is-5">
          <h4 class="title is-5 has-text-centered">MMAudio</h4>
          <video class="comparison-video" controls muted loop height="100%">
            <source src="static/videos/mmaudio_4.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <p class="has-text-centered mt-2">Prompt: cat eating, explosion, liquid, arrow release whoosh </p>
        </div>
        <div class="column is-5">
          <h4 class="title is-5 has-text-centered">Our Method</h4>
          <video class="comparison-video" controls muted loop height="100%">
            <source src="static/videos/lvas_agent_4.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
          <p class="has-text-centered mt-2"> Reflect more sound effects. </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video comparison section -->

<style>
.comparison-video {
  width: 100%;
  border-radius: 4px;
  box-shadow: 0 4px 8px rgba(0,0,0,0.1);
}
</style>

<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">

            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->

<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->

<!-- <section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Acknowledgements</h2>
    <div class="content">
      <p>We would like to express our gratitude to Professor Li Liu for her valuable suggestions 
         on the improvement of the audio-video alignment method for this work.</p>
    </div>
  </div>
</section> -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <!-- <h2 class="title">BibTeX</h2> -->
      <pre><code>
        @misc{zhang2025longvideoaudiosynthesismultiagent,
        title={Long-Video Audio Synthesis with Multi-Agent Collaboration}, 
        author={Yehang Zhang and Xinli Xu and Xiaojie Xu and Li Liu and Yingcong Chen},
        year={2025},
        eprint={2503.10719},
        archivePrefix={arXiv},
        primaryClass={cs.CV},
        url={https://arxiv.org/abs/2503.10719}, 
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>